"""
AdaBoostç®—æ³• (Adaptive Boosting)
æå‡æ–¹æ³• - è‡ªé€‚åº”æå‡ç®—æ³•

ç®—æ³•åŸç†:
1. é€šè¿‡æ”¹å˜è®­ç»ƒæ ·æœ¬çš„æƒé‡ï¼Œå­¦ä¹ å¤šä¸ªå¼±åˆ†ç±»å™¨
2. å°†è¿™äº›å¼±åˆ†ç±»å™¨è¿›è¡Œçº¿æ€§ç»„åˆï¼Œæ„æˆå¼ºåˆ†ç±»å™¨
3. åŠ å¤§åˆ†ç±»è¯¯å·®ç‡å°çš„å¼±åˆ†ç±»å™¨çš„æƒé‡
4. å‡å°åˆ†ç±»è¯¯å·®ç‡å¤§çš„å¼±åˆ†ç±»å™¨çš„æƒé‡

åŸºæœ¬å¼±åˆ†ç±»å™¨:
- ä½¿ç”¨å†³ç­–æ ‘æ¡©ï¼ˆdecision stumpï¼‰
- å•å±‚å†³ç­–æ ‘ï¼Œåªä½¿ç”¨ä¸€ä¸ªç‰¹å¾è¿›è¡Œåˆ†ç±»
- é˜ˆå€¼åˆ†ç±»å™¨ï¼šv=1 if x>threshold else v=-1

ç®—æ³•æµç¨‹:
1. åˆå§‹åŒ–æ ·æœ¬æƒé‡åˆ†å¸ƒ
2. å¯¹æ¯è½®è¿­ä»£ï¼š
   - ä½¿ç”¨å½“å‰æƒé‡åˆ†å¸ƒè®­ç»ƒå¼±åˆ†ç±»å™¨
   - è®¡ç®—å¼±åˆ†ç±»å™¨çš„è¯¯å·®ç‡
   - è®¡ç®—å¼±åˆ†ç±»å™¨çš„æƒé‡
   - æ›´æ–°æ ·æœ¬æƒé‡åˆ†å¸ƒ
3. ç»„åˆæ‰€æœ‰å¼±åˆ†ç±»å™¨

ç‰¹ç‚¹:
- ä¸æ”¹å˜è®­ç»ƒæ•°æ®ï¼Œæ”¹å˜æ ·æœ¬æƒé‡
- æå‡å‡†ç¡®ç‡ï¼Œé™ä½åå·®
- å¯¹å™ªå£°æ•æ„Ÿï¼Œå®¹æ˜“è¿‡æ‹Ÿåˆ
- è®­ç»ƒè¯¯å·®ä»¥æŒ‡æ•°é€Ÿç‡ä¸‹é™

é€‚ç”¨åœºæ™¯:
- äºŒåˆ†ç±»é—®é¢˜
- æé«˜å¼±åˆ†ç±»å™¨æ€§èƒ½
- ç‰¹å¾é€‰æ‹©
- é›†æˆå­¦ä¹ 
"""

import numpy as np
import matplotlib.pyplot as plt

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']  # macOS
plt.rcParams['axes.unicode_minus'] = False


class DecisionStump:
    """å†³ç­–æ ‘æ¡© - å•å±‚å†³ç­–æ ‘"""
    
    def __init__(self):
        self.threshold = None  # åˆ†ç±»é˜ˆå€¼
        self.direction = None  # åˆ†ç±»æ–¹å‘ï¼š1è¡¨ç¤ºx>thresholdæ—¶é¢„æµ‹ä¸º1ï¼Œ-1ç›¸å
        self.feature_index = 0  # ç‰¹å¾ç´¢å¼•ï¼ˆæœ¬ä¾‹åªæœ‰ä¸€ä¸ªç‰¹å¾ï¼‰
        
    def predict(self, X):
        """é¢„æµ‹"""
        n_samples = X.shape[0]
        predictions = np.ones(n_samples)
        
        if self.direction == 1:
            # x <= threshold é¢„æµ‹ä¸º-1
            predictions[X[:, self.feature_index] <= self.threshold] = -1
        else:
            # x > threshold é¢„æµ‹ä¸º-1
            predictions[X[:, self.feature_index] > self.threshold] = 1
        
        return predictions


class AdaBoost:
    """AdaBoostç®—æ³•"""
    
    def __init__(self, n_estimators=3):
        """
        å‚æ•°:
            n_estimators: å¼±åˆ†ç±»å™¨æ•°é‡
        """
        self.n_estimators = n_estimators
        self.estimators = []  # å­˜å‚¨å¼±åˆ†ç±»å™¨
        self.estimator_weights = []  # å­˜å‚¨å¼±åˆ†ç±»å™¨æƒé‡
        self.estimator_errors = []  # å­˜å‚¨å¼±åˆ†ç±»å™¨è¯¯å·®
        
    def fit(self, X, y, verbose=True):
        """
        è®­ç»ƒAdaBooståˆ†ç±»å™¨
        
        å‚æ•°:
            X: è®­ç»ƒæ ·æœ¬ (n_samples, n_features)
            y: æ ‡ç­¾ (n_samples,) å–å€¼ä¸º+1æˆ–-1
        """
        n_samples, n_features = X.shape
        
        if verbose:
            print("="*70)
            print("AdaBoostç®—æ³•è®­ç»ƒ")
            print("="*70)
            print(f"è®­ç»ƒæ ·æœ¬æ•°: {n_samples}")
            print(f"ç‰¹å¾ç»´åº¦: {n_features}")
            print(f"å¼±åˆ†ç±»å™¨æ•°é‡: {self.n_estimators}")
            print()
            
            print("è®­ç»ƒæ•°æ®:")
            print("-"*70)
            for i in range(n_samples):
                print(f"  æ ·æœ¬ {i}: x = {X[i, 0]:.1f}  â†’  y = {y[i]:+d}")
            print()
        
        # åˆå§‹åŒ–æ ·æœ¬æƒé‡ D_1(i) = 1/N
        weights = np.ones(n_samples) / n_samples
        
        if verbose:
            print("åˆå§‹æƒé‡åˆ†å¸ƒ:")
            print(f"  D_1 = {weights}")
            print()
        
        # è®­ç»ƒMä¸ªå¼±åˆ†ç±»å™¨
        for m in range(self.n_estimators):
            if verbose:
                print(f"{'='*70}")
                print(f"ç¬¬ {m+1} è½®è¿­ä»£")
                print(f"{'='*70}")
                print(f"å½“å‰æƒé‡åˆ†å¸ƒ D_{m+1}:")
                for i in range(n_samples):
                    print(f"  w_{i} = {weights[i]:.4f}")
                print()
            
            # è®­ç»ƒå¼±åˆ†ç±»å™¨ - æ‰¾åˆ°æœ€ä½³é˜ˆå€¼
            best_stump = None
            min_error = float('inf')
            best_predictions = None
            
            # å°è¯•æ‰€æœ‰å¯èƒ½çš„é˜ˆå€¼
            feature_values = X[:, 0]
            # å€™é€‰é˜ˆå€¼ï¼šæ ·æœ¬å€¼ä¹‹é—´çš„ä¸­ç‚¹
            thresholds = []
            sorted_values = np.sort(np.unique(feature_values))
            for i in range(len(sorted_values) - 1):
                thresholds.append((sorted_values[i] + sorted_values[i+1]) / 2)
            
            # ä¹Ÿå°è¯•è¾¹ç•Œå€¼
            thresholds = [-0.5] + thresholds + [sorted_values[-1] + 0.5]
            
            if verbose:
                print(f"å°è¯•çš„é˜ˆå€¼: {thresholds}")
                print()
            
            # å¯¹æ¯ä¸ªé˜ˆå€¼å’Œæ–¹å‘è¿›è¡Œå°è¯•
            for threshold in thresholds:
                for direction in [1, -1]:
                    stump = DecisionStump()
                    stump.threshold = threshold
                    stump.direction = direction
                    
                    predictions = stump.predict(X)
                    
                    # è®¡ç®—åŠ æƒè¯¯å·®
                    misclassified = (predictions != y)
                    error = np.sum(weights[misclassified])
                    
                    if error < min_error:
                        min_error = error
                        best_stump = stump
                        best_predictions = predictions
            
            if verbose:
                print(f"é€‰æ‹©çš„å¼±åˆ†ç±»å™¨ G_{m+1}(x):")
                print(f"  é˜ˆå€¼: {best_stump.threshold:.1f}")
                print(f"  æ–¹å‘: {'x > threshold â†’ +1' if best_stump.direction == 1 else 'x <= threshold â†’ +1'}")
                print()
                
                print(f"åˆ†ç±»ç»“æœ:")
                for i in range(n_samples):
                    pred = int(best_predictions[i])
                    true = int(y[i])
                    status = "âœ“" if pred == true else "âœ—"
                    print(f"  æ ·æœ¬ {i}: é¢„æµ‹ {pred:+d}, çœŸå® {true:+d}  {status}")
                print()
            
            # è®¡ç®—è¯¯å·®ç‡ e_m
            error_rate = min_error
            self.estimator_errors.append(error_rate)
            
            if verbose:
                print(f"è¯¯å·®ç‡ e_{m+1} = {error_rate:.4f}")
            
            # è®¡ç®—å¼±åˆ†ç±»å™¨æƒé‡ Î±_m
            # Î±_m = 0.5 * ln((1 - e_m) / e_m)
            if error_rate == 0:
                alpha = 10  # é¿å…é™¤ä»¥0ï¼Œç»™ä¸€ä¸ªå¤§æƒé‡
            elif error_rate >= 0.5:
                alpha = 0  # è¯¯å·®ç‡è¿‡å¤§ï¼Œæƒé‡ä¸º0
            else:
                alpha = 0.5 * np.log((1 - error_rate) / error_rate)
            
            self.estimator_weights.append(alpha)
            
            if verbose:
                print(f"åˆ†ç±»å™¨æƒé‡ Î±_{m+1} = 0.5 * ln((1 - {error_rate:.4f}) / {error_rate:.4f}) = {alpha:.4f}")
                print()
            
            # ä¿å­˜å¼±åˆ†ç±»å™¨
            self.estimators.append(best_stump)
            
            # æ›´æ–°æ ·æœ¬æƒé‡
            # w_{m+1,i} = w_{m,i} * exp(-Î±_m * y_i * G_m(x_i)) / Z_m
            weights = weights * np.exp(-alpha * y * best_predictions)
            
            # å½’ä¸€åŒ–
            Z_m = np.sum(weights)
            weights = weights / Z_m
            
            if verbose:
                print(f"æ›´æ–°æƒé‡:")
                print(f"  å½’ä¸€åŒ–å› å­ Z_{m+1} = {Z_m:.4f}")
                print(f"  æ–°æƒé‡åˆ†å¸ƒ D_{m+2}:")
                for i in range(n_samples):
                    print(f"    w_{i} = {weights[i]:.4f}")
                print()
        
        if verbose:
            print("="*70)
            print("è®­ç»ƒå®Œæˆï¼")
            print("="*70)
            print()
            
            print("æœ€ç»ˆçš„å¼ºåˆ†ç±»å™¨:")
            print("-"*70)
            print("f(x) = sign(", end="")
            for m in range(self.n_estimators):
                stump = self.estimators[m]
                alpha = self.estimator_weights[m]
                if m > 0:
                    print(" + ", end="")
                print(f"{alpha:.4f}Â·G_{m+1}(x)", end="")
            print(")")
            print()
            
            print("å„å¼±åˆ†ç±»å™¨:")
            for m in range(self.n_estimators):
                stump = self.estimators[m]
                alpha = self.estimator_weights[m]
                error = self.estimator_errors[m]
                direction_str = "x > " if stump.direction == 1 else "x <= "
                print(f"  G_{m+1}(x): {direction_str}{stump.threshold:.1f} â†’ +1, å¦åˆ™ -1")
                print(f"    Î±_{m+1} = {alpha:.4f}, e_{m+1} = {error:.4f}")
            print("="*70)
    
    def predict(self, X):
        """é¢„æµ‹"""
        # è®¡ç®—åŠ æƒæŠ•ç¥¨
        predictions = np.zeros(X.shape[0])
        
        for alpha, estimator in zip(self.estimator_weights, self.estimators):
            predictions += alpha * estimator.predict(X)
        
        return np.sign(predictions)
    
    def predict_scores(self, X):
        """è¿”å›å†³ç­–å‡½æ•°çš„å€¼ï¼ˆç”¨äºå¯è§†åŒ–ï¼‰"""
        scores = np.zeros(X.shape[0])
        
        for alpha, estimator in zip(self.estimator_weights, self.estimators):
            scores += alpha * estimator.predict(X)
        
        return scores
    
    def plot_results(self, X, y):
        """å¯è§†åŒ–AdaBoostç»“æœ"""
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        
        # å›¾1: å¼±åˆ†ç±»å™¨çš„å†³ç­–è¾¹ç•Œ
        ax1 = axes[0, 0]
        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
        xx = np.linspace(x_min, x_max, 1000).reshape(-1, 1)
        
        for i, (stump, alpha, error) in enumerate(zip(self.estimators, 
                                                       self.estimator_weights, 
                                                       self.estimator_errors)):
            yy = stump.predict(xx)
            label = f'G_{i+1}(x): é˜ˆå€¼={stump.threshold:.1f}, Î±={alpha:.3f}, e={error:.3f}'
            ax1.plot(xx, yy + i*0.1, label=label, linewidth=2, alpha=0.7)
        
        # ç»˜åˆ¶è®­ç»ƒæ ·æœ¬
        for label_val in [1, -1]:
            mask = y == label_val
            ax1.scatter(X[mask, 0], np.zeros(np.sum(mask)), 
                       c='red' if label_val == 1 else 'blue',
                       marker='o' if label_val == 1 else 's',
                       s=150, edgecolors='black', linewidths=2,
                       label=f'çœŸå®ç±»åˆ« {label_val:+d}', zorder=5)
        
        ax1.set_xlabel('x', fontsize=12)
        ax1.set_ylabel('é¢„æµ‹å€¼', fontsize=12)
        ax1.set_title('å„å¼±åˆ†ç±»å™¨çš„å†³ç­–å‡½æ•°', fontsize=14, fontweight='bold')
        ax1.legend(loc='best', fontsize=9)
        ax1.grid(True, alpha=0.3)
        ax1.axhline(y=0, color='black', linestyle='--', linewidth=1)
        
        # å›¾2: å¼ºåˆ†ç±»å™¨çš„å†³ç­–å‡½æ•°
        ax2 = axes[0, 1]
        scores = self.predict_scores(xx)
        predictions = np.sign(scores)
        
        ax2.plot(xx, scores, 'g-', linewidth=3, label='f(x) = Î£ Î±_mÂ·G_m(x)')
        ax2.axhline(y=0, color='black', linestyle='--', linewidth=2, label='å†³ç­–è¾¹ç•Œ')
        ax2.fill_between(xx.ravel(), -10, scores.ravel(), 
                         where=(scores.ravel() > 0), alpha=0.3, color='red', label='é¢„æµ‹ä¸º+1åŒºåŸŸ')
        ax2.fill_between(xx.ravel(), -10, scores.ravel(), 
                         where=(scores.ravel() < 0), alpha=0.3, color='blue', label='é¢„æµ‹ä¸º-1åŒºåŸŸ')
        
        # ç»˜åˆ¶è®­ç»ƒæ ·æœ¬
        for label_val in [1, -1]:
            mask = y == label_val
            ax2.scatter(X[mask, 0], np.zeros(np.sum(mask)), 
                       c='red' if label_val == 1 else 'blue',
                       marker='o' if label_val == 1 else 's',
                       s=150, edgecolors='black', linewidths=2,
                       label=f'çœŸå®ç±»åˆ« {label_val:+d}', zorder=5)
        
        ax2.set_xlabel('x', fontsize=12)
        ax2.set_ylabel('f(x)', fontsize=12)
        ax2.set_title('å¼ºåˆ†ç±»å™¨çš„å†³ç­–å‡½æ•°', fontsize=14, fontweight='bold')
        ax2.legend(loc='best', fontsize=10)
        ax2.grid(True, alpha=0.3)
        ax2.set_ylim(-3, 3)
        
        # å›¾3: åˆ†ç±»å™¨æƒé‡
        ax3 = axes[1, 0]
        x_pos = np.arange(len(self.estimator_weights))
        bars = ax3.bar(x_pos, self.estimator_weights, color='steelblue', 
                      edgecolor='black', linewidth=1.5, alpha=0.8)
        
        # åœ¨æŸ±å­ä¸Šæ ‡æ³¨æ•°å€¼
        for i, (bar, weight) in enumerate(zip(bars, self.estimator_weights)):
            height = bar.get_height()
            ax3.text(bar.get_x() + bar.get_width()/2., height,
                    f'{weight:.4f}',
                    ha='center', va='bottom', fontsize=11, fontweight='bold')
        
        ax3.set_xlabel('å¼±åˆ†ç±»å™¨', fontsize=12)
        ax3.set_ylabel('æƒé‡ Î±', fontsize=12)
        ax3.set_title('å„å¼±åˆ†ç±»å™¨çš„æƒé‡', fontsize=14, fontweight='bold')
        ax3.set_xticks(x_pos)
        ax3.set_xticklabels([f'G_{i+1}' for i in range(len(self.estimator_weights))])
        ax3.grid(True, alpha=0.3, axis='y')
        
        # å›¾4: è¯¯å·®ç‡
        ax4 = axes[1, 1]
        x_pos = np.arange(len(self.estimator_errors))
        bars = ax4.bar(x_pos, self.estimator_errors, color='coral', 
                      edgecolor='black', linewidth=1.5, alpha=0.8)
        
        # åœ¨æŸ±å­ä¸Šæ ‡æ³¨æ•°å€¼
        for i, (bar, error) in enumerate(zip(bars, self.estimator_errors)):
            height = bar.get_height()
            ax4.text(bar.get_x() + bar.get_width()/2., height,
                    f'{error:.4f}',
                    ha='center', va='bottom', fontsize=11, fontweight='bold')
        
        ax4.set_xlabel('å¼±åˆ†ç±»å™¨', fontsize=12)
        ax4.set_ylabel('è¯¯å·®ç‡ e', fontsize=12)
        ax4.set_title('å„å¼±åˆ†ç±»å™¨çš„è¯¯å·®ç‡', fontsize=14, fontweight='bold')
        ax4.set_xticks(x_pos)
        ax4.set_xticklabels([f'G_{i+1}' for i in range(len(self.estimator_errors))])
        ax4.grid(True, alpha=0.3, axis='y')
        ax4.set_ylim(0, max(self.estimator_errors) * 1.2)
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾ç‰‡
        filename = f'adaboost_M{self.n_estimators}.png'
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        print(f"\nå›¾åƒå·²ä¿å­˜è‡³: {filename}")
        plt.show()


def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "ğŸ¯ "*20)
    print("AdaBoostç®—æ³•æ¼”ç¤º")
    print("ğŸ¯ "*20 + "\n")
    
    # è®­ç»ƒæ•°æ®ï¼ˆæèˆªã€Šç»Ÿè®¡å­¦ä¹ æ–¹æ³•ã€‹ä¾‹8.1ï¼‰
    X_train = np.array([
        [0],
        [1],
        [2],
        [3],
        [4],
        [5],
        [6],
        [7],
        [8],
        [9]
    ])
    
    y_train = np.array([1, 1, 1, -1, -1, -1, 1, 1, 1, -1])
    
    # åˆ›å»ºå¹¶è®­ç»ƒAdaBoost
    adaboost = AdaBoost(n_estimators=3)
    adaboost.fit(X_train, y_train)
    
    # åœ¨è®­ç»ƒé›†ä¸Šè¯„ä¼°
    print("\nè®­ç»ƒé›†é¢„æµ‹ç»“æœ:")
    print("-"*70)
    y_pred = adaboost.predict(X_train)
    scores = adaboost.predict_scores(X_train)
    
    for i, (x, y_true, y_p, score) in enumerate(zip(X_train, y_train, y_pred, scores)):
        result = "âœ“" if y_p == y_true else "âœ—"
        print(f"  æ ·æœ¬ {i}: x = {x[0]:.1f}  â†’  f(x) = {score:+7.4f}  â†’  é¢„æµ‹: {int(y_p):+d}  çœŸå®: {y_true:+d}  {result}")
    
    # è®¡ç®—å‡†ç¡®ç‡
    accuracy = np.mean(y_pred == y_train) * 100
    print(f"\nè®­ç»ƒé›†å‡†ç¡®ç‡: {accuracy:.2f}%")
    print()
    
    # æµ‹è¯•æ–°æ ·æœ¬
    print("æ–°æ ·æœ¬é¢„æµ‹:")
    print("-"*70)
    X_test = np.array([[0.5], [2.5], [5.5], [7.5]])
    
    for x in X_test:
        y_pred = int(adaboost.predict(x.reshape(1, -1))[0])
        score = adaboost.predict_scores(x.reshape(1, -1))[0]
        print(f"  x = {x[0]:.1f}  â†’  f(x) = {score:+7.4f}  â†’  é¢„æµ‹: {y_pred:+d}")
    print()
    
    # å¯è§†åŒ–
    adaboost.plot_results(X_train, y_train)
    
    print("\n" + "="*70)
    print("æ¼”ç¤ºå®Œæˆï¼")
    print("="*70 + "\n")


if __name__ == "__main__":
    main()
